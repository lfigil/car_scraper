{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on Used Car Market (2021 - 2024)\n",
    "\n",
    "## Objective\n",
    "- Analize **used** car market inventory levels and the price of different automobiles makers, such as, Toyata, Honda, and Mazda, for their SUV and Sedan models.\n",
    "- Find the best `deal` based on mileage, price, and others factors.\n",
    "- Possible make purchase in the future based on any insights.\n",
    "\n",
    "## Methodology\n",
    "- Since there are several models and trims for each different automobile maker, I will be focusing in some specific model. In the SUV category: `RAV4`, `CX5`, `CR-V` and `Pilot`. For the Sedan category: `Corolla` `Camry`, `Mazda3`, `Mazda6`, `Civic`.\n",
    "- I will be focusing on cars from 2021 to 2024.\n",
    "- I will need as much information as I can gather from a single website, such as, current car price, mileage, vehicle history, dealer, days on market. \n",
    "- I will be gathering this information from **edmunds** website using the `Selenium` library.\n",
    "\n",
    "### Hypothesis\n",
    "- Depending on how much information I am able to gather, I will have different hypothesis.\n",
    "- My number one hypothesis is that the `price` of a car depends on the number of `mileage`. Low mileage means, high price and vice versa.\n",
    "- My second hypothesis is that newer models have a higher price.\n",
    "- Finding a `good` deal on a used car will be a tough task since no two used cars are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data_list, file_path):\n",
    "    \"\"\"Creates a new file if does not exists and appends a list\"\"\"\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    # Check if the CSV file already exists\n",
    "    file_exists = pd.io.common.file_exists(file_path)\n",
    "    \n",
    "    # If the file exists, append data without headers\n",
    "    # Otherwise, write data with headers\n",
    "    df.to_csv(file_path, mode='a', header=not file_exists, index=False)\n",
    "    \n",
    "    print(f\"Saving {len(df)} listings...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(text):\n",
    "    \"\"\"Extracts mileage and accidents/owners/usage information from a given text string.\"\"\"\n",
    "    \n",
    "    # Define regex pattern for mileage\n",
    "    mileage_pattern = r'(\\d{1,3}(?:,\\d{3})*|\\d+) miles'\n",
    "    \n",
    "    # Define regex pattern for accidents/owners/usage\n",
    "    # Match the entire line(s) after mileage\n",
    "    accidents_owners_usage_pattern = r'(?<=miles\\n)(.*)'\n",
    "    \n",
    "    # Search for mileage\n",
    "    mileage_match = re.search(mileage_pattern, text)\n",
    "    if mileage_match:\n",
    "        mileage = mileage_match.group(0)\n",
    "    else:\n",
    "        mileage = None\n",
    "    \n",
    "    # Search for accidents/owners/usage\n",
    "    accidents_owners_usage_match = re.search(accidents_owners_usage_pattern, text, re.DOTALL)\n",
    "    if accidents_owners_usage_match:\n",
    "        accidents_owners_usage = accidents_owners_usage_match.group(1)\n",
    "        accidents_owners_usage = accidents_owners_usage.split(\"\\n\")[0]\n",
    "    else:\n",
    "        accidents_owners_usage = None\n",
    "    \n",
    "    # Return the extracted information as a dictionary\n",
    "    return {\n",
    "        'mileage': mileage,\n",
    "        'accidents_owners_usage': accidents_owners_usage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_maker(text):\n",
    "    \"\"\"accepts a string and returns a dictionary based on the contents of the string. \n",
    "    If a string line contains a semicolon (:), split the line into key and value, and add them to \n",
    "    the dictionary. If a string line does not contain a semicolon, generate a key like k1, k2, and so on, \n",
    "    and assign the line content as the value.\"\"\"\n",
    "\n",
    "    result_dict = {}\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line:\n",
    "            if \":\" in line:\n",
    "                # Split by semicolon\n",
    "                k, v = line.split(\":\", 1)\n",
    "\n",
    "                k = k.strip()\n",
    "                v = v.strip()\n",
    "\n",
    "                # Add key value pair to dict\n",
    "                result_dict[k] = v\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_scraper(driver):\n",
    "    \"\"\"Scrapes data from the current page and returns a list of dictionaries with items scraped.\"\"\"\n",
    "    vehicle_listings = []\n",
    "    next_page = False\n",
    "    next_page_url = \"\"\n",
    "\n",
    "    try:\n",
    "        # Find the list of listings\n",
    "        unorder_list = driver.find_element(By.CSS_SELECTOR, \"ul.usurp-card-list.list-unstyled.align-items-stretch.row\")\n",
    "        listings = unorder_list.find_elements(By.CSS_SELECTOR, \"li.d-flex.mb-0_75.mb-md-1_5.col-12.col-md-6\")\n",
    "        \n",
    "        # Loop through each listing\n",
    "        for item in listings:\n",
    "            try:\n",
    "                # Extract vehicle information\n",
    "                car_url = item.find_element(By.CSS_SELECTOR, 'a.usurp-inventory-card-vdp-link').get_attribute(\"href\")\n",
    "                y_m_m = item.find_element(By.CSS_SELECTOR, 'div.size-16.text-cool-gray-10.font-weight-bold.mb-0_5').text\n",
    "                trim_style = item.find_element(By.CSS_SELECTOR, 'div.font-weight-normal.size-14.text-cool-gray-30').text\n",
    "                price = item.find_element(By.CSS_SELECTOR, 'span.heading-3').text\n",
    "\n",
    "                # Extract additional information as dictionary\n",
    "                details = item.find_element(By.CSS_SELECTOR, 'div.text-gray-darker.row').text\n",
    "                details_dict = extract_details(details)\n",
    "\n",
    "                summary = item.find_element(By.CSS_SELECTOR, 'summary.px-0.py-0.small.text-primary-darker.d-flex.align-items-center.size-16.mt-1.justify-content-end')\n",
    "                if not summary.is_selected():\n",
    "                    summary.click()\n",
    "                    time.sleep(0.5)  # Add a delay to allow content to load\n",
    "\n",
    "                # Extract vehicle history and listing information\n",
    "                history = item.find_element(By.CSS_SELECTOR, 'section.srp-card-vehicle-history.mb-1').find_element(By.CSS_SELECTOR, 'div.row').text\n",
    "                history_dict = dict_maker(history)\n",
    "\n",
    "                listing_info = item.find_element(By.CSS_SELECTOR, 'details.view-more').find_elements(By.CSS_SELECTOR, 'p.xsmall.mb-1')[-1].text\n",
    "                listing_info_dict = dict_maker(listing_info)\n",
    "\n",
    "                # Create a dictionary with vehicle information\n",
    "                vehicle_dict = {\n",
    "                    'year_make_model': y_m_m,\n",
    "                    'trim_style': trim_style,\n",
    "                    'price': price,\n",
    "                    'url': car_url\n",
    "                }\n",
    "\n",
    "                # Update vehicle_dict with additional details, history, and listing information\n",
    "                vehicle_dict.update(details_dict)\n",
    "                vehicle_dict.update(history_dict)\n",
    "                vehicle_dict.update(listing_info_dict)\n",
    "\n",
    "                # Add the vehicle_dict to vehicle_listings\n",
    "                vehicle_listings.append(vehicle_dict)\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                # Handle missing elements by skipping the listing\n",
    "                continue\n",
    "            except StaleElementReferenceException:\n",
    "                # Skip the listing if it's no longer valid\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unhandled error processing listing: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Find and handle the \"Next\" button for pagination\n",
    "        next_buttons = driver.find_elements(By.CSS_SELECTOR, 'a.pagination-btn.rounded.d-flex.align-items-center.justify-content-center.text-blue-30.mx-1_5')\n",
    "        \n",
    "        if len(next_buttons) > 1:  # Ensure there is more than one button available\n",
    "            next_button = next_buttons[1]  # Assuming the second button is the \"Next\" button\n",
    "\n",
    "            if next_button.get_attribute(\"aria-disabled\") == 'true':\n",
    "                next_page = False\n",
    "                next_page_url = \"\"\n",
    "            else:\n",
    "                next_page = True\n",
    "                next_page_url = next_button.get_attribute(\"href\")\n",
    "                next_button.click()\n",
    "                time.sleep(0.5)  # Add a delay for navigation\n",
    "                \n",
    "                print(f\"NEXT PAGE: {next_page_url}\")\n",
    "\n",
    "        return vehicle_listings, next_page, next_page_url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OUTER ERROR: {e}\")\n",
    "        return vehicle_listings, False, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialize a new WebDriver session\n",
    "def initialize_webdriver(url):\n",
    "    # Set up Selenium options\n",
    "    options = Options()\n",
    "    options.add_argument('--incognito')\n",
    "    \n",
    "    # Create a new WebDriver instance\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # Load the URL\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(2)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "# Define a function to close the WebDriver instance\n",
    "def close_webdriver(driver):\n",
    "    # Close the WebDriver instance\n",
    "    if driver:\n",
    "        driver.quit()\n",
    "\n",
    "# Define the main function to perform the scraping and navigation\n",
    "def main():\n",
    "    default_path = \"https://www.edmunds.com/inventory/srp.html?make=audi&inventorytype=used%2Ccpo\"\n",
    "    save_file_path = 'folder_test/file_text.csv'\n",
    "    \n",
    "    # Initialize the WebDriver\n",
    "    driver = initialize_webdriver(default_path)\n",
    "    \n",
    "    while True:\n",
    "        # Scrape the page and navigate to the next page\n",
    "        vehicles_list, next_page, new_url = page_scraper(driver)\n",
    "        \n",
    "        # Save the scraped data to CSV\n",
    "        save_to_csv(vehicles_list, save_file_path)\n",
    "        \n",
    "        # Check if there is a next page to navigate to\n",
    "        if next_page:\n",
    "            # Close the current WebDriver instance\n",
    "            close_webdriver(driver)\n",
    "            \n",
    "            # Initialize a new WebDriver instance with the updated URL\n",
    "            driver = initialize_webdriver(new_url)\n",
    "            \n",
    "            # Add a delay between page navigations\n",
    "            time.sleep(0.5)\n",
    "        else:\n",
    "            # No more pages to navigate to, break the loop\n",
    "            break\n",
    "    \n",
    "    # Close the WebDriver when done\n",
    "    close_webdriver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
